var tipuesearch = {"pages": [{'title': 'About', 'text': 'This is  https://github.com/mdecourse/cmstemplate \n 電腦輔助設計室與協同設計室行事曆 \n 全頁檢視 \n \n', 'tags': '', 'url': 'About.html'}, {'title': '三道牆理論', 'text': 'KMOLab 所開設課程目的是將擋在機械工程師面前的三道牆, 直接利用課程講授的過程, 一一呈現, 讓大家有及時找出突破這三道障礙的機會, 不僅讓各自的潛能有所發揮, 同時也希望大家能更自在地面對未來的更多挑戰. 這三道牆分別是: \n 理論基礎障礙 實務練習障礙 確立目標障礙 \n 理論基礎障礙 \n 所謂的理論基礎障礙就是技職體系學生在高中階段經常疏忽的英文, 數學與邏輯思考與獲取學問的基本能力. 也就是英文聽說讀寫的基本能力, 數學基本能力與了解如何透過邏輯思考解題, 並且學習如何發問, 如何與人協同合作解決問題的能力. \n 實務練習障礙 \n 第二道牆則是實務練習障礙, 許多人不願意花時間在突破上述第一道障礙的原因, 通常是因為不知道學習這些相對抽象的知識有甚麼用處? 因此, 為了凸顯突破第一道牆的重要性, 就必須要透過實際的課程案例, 讓大家了解一旦能突破第一道牆的障礙後, 養成持續學習這些理論基礎內容之後, 就可以相對用比較有效率的方式解決各種問題. \n 但是這需要學習者付出時間與耐性, 當面對完全陌生議題時, 就必須檢討是否第一道牆仍然卡在自己與解決方案中間. 然後用心不斷思考, 探索與練習之後, 若還是無法解決問題. 就必須要先試著描述問題後再尋求他人的協助. \n 假如能有以上的正確學習態度, 就有機會在面對各種問題時, 持續突破前面的兩道牆, 然後看到自己所追求的第三道牆, 並且此後能夠竭盡全力, 翻閱第三道牆的障礙, 積極達成預定目標. \n 確立目標障礙 \n 你的人生目標是甚麼?', 'tags': '', 'url': '三道牆理論.html'}, {'title': 'Network', 'text': "Understanding bandwidth Bandwidth refers to the data rate that is supported by the network connection or the interfaces that connect to the network. It represents both volume and time, representing the amount of data that can be transmitted between two points in a set period of time. It is usually expressed in terms of bits per second (bps), or sometimes in bytes per second (Bps). Network bandwidth represents the capacity of the network connection, though it's important to understand the distinction between theoretical throughput and real-world results when figuring out the right bandwidth formula for your network. For example, a 1000BASE-T -- which uses unshielded twisted-pair cables -- Gigabit Ethernet (GbE) network can theoretically support 1,000 megabits per second (Mbps), but this level can never really be achieved in practice because of hardware and systems software overhead. One point to consider when thinking about how to calculate bandwidth needs on your network is this: Bandwidth should not be confused with throughput, which refers to speed. While high-bandwidth networks are often fast, that is not always the case. A helpful metaphor when thinking about bandwidth is cars on a highway. A high-bandwidth network is like a six-lane highway that can fit hundreds of cars at any given moment. A low-bandwidth network is like a single-lane road in which one car queues directly behind another. Although the large highway is likely to move vehicles faster, rush-hour traffic can easily bring cars and trucks to a standstill. Or, perhaps, the cars cannot get onto the highway quickly because it's clogged with large delivery trucks that take up a lot of space on the road. Similarly, even a high-bandwidth network can run slowly in the face of problems, such as congestion and bandwidth-hungry applications. These very points make calculating bandwidth requirements a challenge, yet the consequences of getting the bandwidth formula wrong are considerable. If you don't procure enough bandwidth, you all but guarantee the network will run slowly. However, significantly overprovisioning bandwidth can be cost-prohibitive for most enterprises. So, how do you determine the right formula that will meet your bandwidth requirements? The process begins with asking the right questions: What applications are users running, and what is the performance service-level agreement for these applications? I know some network managers who are only concerned with how many users are on a virtual LAN. What you really need to know is what the users will be doing on the network. It's possible that 200 users will cause less of a bottleneck than a group of three users that really beats the heck out of the network because of some funky client-server application or extensive use of a bandwidth-heavy service, like high-definition video conferencing. \n \n 了解  https://www.wireshark.org  的用法, 並藉以提升網路頻寬的使用效能及安全. \n 近端下載 \n http://a.kmol.info:88/Wireshark-win64-3.4.2.exe", 'tags': '', 'url': 'Network.html'}, {'title': 'Switch', 'text': 'Not all switches are created equal. \n 來源 \n https://www.cisco.com/c/en/us/products/switches/index.html#~products \n https://www.cisco.com/c/dam/en/us/products/collateral/switches/catalyst-9300-series-switches/nb-06-upgrading-cat-9300-fc-cte-en.pdf \n internally to a switch a specialized hardware is needed to move frames between ports. This specific part can be called backplane (背板) or in some cases we talk of switching fabric (交換結構). When the forwarding capabilities of a backplane or switching fabric are greater then the sum of speeds of all ports (counted twice one for tx and one rx direction) we call the switching fabric non blocking: traffic between a pair of ports is not influenced by what traffic is exchanged on all other ports. The forwarding rate is expressed in packet per seconds and expresses how many packets per second are needed to reach a certain traffic volume (throughpout) Clearly forwarding rate depends on frame size. Ideally a backplane switching fabric should be non blocking for every frame size including the smallest ones (64 bytes in ethernet standard) but in reality most devices can be non blocking for an average size of 400 bytes. bandwidth: the speed of traffic. to convert between forwarding rate and used bandwidth we need to take in account some specific aspects of ethernet: each frame has an 8 byte preamble that is used to allow to potential receiver to synchronize with the signal between two frames a minimum silence interval must exist to allow receiver to discriminate between two frames preamble and inter frame gap counts for 20,2 bytes. So given an iP packet of size N the ethernet frame has size N+18\xa0 (header 14 bytes, FCS 4 byte) but counts as (N+18+20,2)*8 on wire 8 is number of bits in a byte with this kind of calculation using frames of minimum size 64 bytes you need 1488000 frames per second and per direction to fill a GE port. Be also aware that all figures you see sum tx and rx directions so if a switch has 100 M pps capability this accounts for a certain number of GE ports at 1 Gbps full duplex. \n Do not confuse the speed of the stackwise ring with the internal switching fabric of each stack member, they are different: the internal switching fabric should be used for traffic between ports on the same stack member device, the stackwise bandwidth should be used when traffic must flow between ports located on different stack members. Note: this is just my assumption about the implementation of stack, it may be different with the dual ring involved also for traffic between two ports on the same member switch. (total lack of so called local switching capabilities). The stack implements a dual ring topology between the member switches that act as an extension of the individual switching fabrics. The speed of the ring for a stack of only 3750-X (stackwise plus) should be 32 Gbps full duplex that allows for a very good interconnection between member switches, but I agree it is not enough to classify the composite switching fabric as not blocking. On the other hand, only models with 10GE ports can be interconnected at comparable speeds. To make a comparison a C6500 equipped with Sup720 generation route processor provides up to 40 Gbps per slot to/from the switching fabric and some linecards are faster then that ( think of\xa0 WS-6708 or WS-6716 with 8 and 16 tengiga ports respectively). About the forwarding capacity in pps: for a 24 ports device is listed as 65.5 Mbps that accounts for 22 GE ports 1Gbps full duplex with 64 byte frames. \n An original series 3750 (or 3560) fabric is 32 Gbps.\xa0 This is different from the stack ring\'s "32 Gbps" (which is really dual 8 Gbps, duplex). An original series 3750 (or 3560) internal fabric, in theory, is oversubscribed by more than 16 gig ports (i.e. the "G" suffixed original models). The terms non-blocking and blocking, when examining switch fabric isn\'t just sufficient bandwidth capacity to forward all port bandwidths, it\'s whether the fabric\'s architecture will block, or not, forwarding of frames even if there\'s "sufficient" bandwidth. For example, you have three ingress ports.\xa0 Two are sending to one egress port (2:1) and the other is sending to other egress port (1:1).\xa0 If 2:1 congestion on the one egress port delays (or blocks) transmission on the 1:1 egress port, you have HOL (head-of-line) blocking even though the internal fabric\'s bandwidth could support each ingress port sending to a separate egress port (all 1:1). StackWise (and StackWise+), when available, use both ring ports. Original StackWise copies ALL member switch traffic to the stack ring.\xa0 Original StackWise source stack member also removes the traffic it placed on the stack ring. StackWise Plus only places unicast traffic on the stack ring when destination is not a local switch port.\xa0 Additionally, destination switch member removes unicast packets.\xa0 (I.e. StackWise+ uses it\'s ring much more intelligently.\xa0 It also has dual 16 Gbps stack ring ports.\xa0 NB:StackWise+, for the most part, reverts to StackWise operation if there\'s a StackWise only member switch in the stack [good reason not to use such mixed stacks].) Bits per second, is the transmission rate supported by the media.\xa0 So, for example, 100 Mbps allows transmission of 100,000,000 bits per seconds.\xa0 However, transferring actual data, in something like physical segments (e.g. frames) uses some of this capacity for both framing overhead and framing delineation, so useful capacity is less than the often quoted bps rate.\xa0 Useful capacity percentage (of overall rate) also generally decreases as frame size decreases.\xa0 (BTW, similar issue with disk media.\xa0 At least disk capacity isn\'t, generally, quoted for its unformatted capacity any longer.) The 25 Mbps throughput is rated for minimum sized packets.\xa0 Larger packets often allow much higher throughput as the packets per second requirement (for same bandwidth) decreases.\xa0 (Sometimes the vendor will document PPS rates for multiple packet sizes.\xa0 Without such documentation, or your own testing, just knowing documented performance for one packet size you cannot accurately predict a device\'s performance for other packet sizes.) \n 來源 \n Switch backplane bandwidth, switching capacity, packet forwarding rate difference Backplane bandwidth refers to the entire switching capacity of the backplane, switching capacity refers to the switching capacity of the CPU, and packet forwarding refers to the capacity of the three-layer forwarding. First, the backplane bandwidth 1. Switch backplane bandwidth meaning \n The backplane bandwidth of the switch, also called the backplane capacity, is the maximum amount of data that can be handled between the switch interface processor or the interface card and the data bus. The backplane bandwidth marks the total data exchange capacity of the switch, in Gbps. The backplane bandwidth of a typical switch ranges from a few Gbps to hundreds of Gbps. The higher the backplane bandwidth of a switch, the better the ability to process data, but at the same time the design cost will be higher. 2. The internal structure of the switch \n The utilization of backplane bandwidth resources is closely related to the internal structure of the switch. At present, the internal structure of the switch mainly has the following types: \n First, a shared memory structure, which relies on a central switching engine to provide a high-performance connection for a full port, and the core engine checks each input packet to determine a route. This method requires a large memory bandwidth and high management cost. Especially with the increase of the switch port, the price of the central memory will be very high, so the switch core becomes the bottleneck of performance realization; \n the second is the cross bus structure, which can Establish a direct point-to-point connection between ports, which is good for single-point transmission, but not suitable for multi-point transmission; \n the third is a hybrid cross-bus structure, which is a hybrid cross-bus implementation. Its design idea is to integrate The cross bus matrix is divided into small cross matrices connected by a high performance bus. The advantage is that the number of cross-buses is reduced, the cost is reduced, and bus contention is reduced; however, the bus connecting the cross-matrix becomes a new performance bottleneck. 3. Linear non-blocking transmission \n The best performance we can buy for the transfer machine is to require linear non-blocking transmission. How do we investigate whether the backplane bandwidth of a switch is sufficient? How to determine whether the design of the switch you bought is reasonable, and there is a blocking structure design? \n Calculation formula: \n A. The sum of the number of all port capacity X ports should be less than the backplane bandwidth, which can realize full-duplex non-blocking switching, which proves that the switch has the conditions of maximizing data exchange performance. \n B. Full configuration throughput (Mbps) = full configuration GE port number × 1.488 Mpps, wherein the theoretical throughput of a Gigabit port with a packet length of 64 bytes is 1.488 Mpps. For example, a switch with up to 64 Gigabit ports should have a full configuration throughput of 64 x 1.488 Mpps = 95.2 Mpps to ensure non-blocking packet switching when all port line speeds are working. Example: If a switch can provide up to 176 Gigabit ports and the declared throughput is less than 261.8 Mpps (176 x 1.488 Mpps = 261.8), then the user has reason to believe that the switch is designed with a blocking structure. \n For 10 Gigabit Ethernet, the packet forwarding rate of a wire-speed port is 14.88 Mpps. \n For Gigabit Ethernet, the packet forwarding rate of a wire-speed port is 1.488 Mpps. \n For Fast Ethernet, the packet forwarding rate of a wire-speed port is 0.1488 Mpps. \n For OC-12 POS ports, the packet forwarding rate of a line rate port is 1.17 Mpps. \n For the POS port of OC-48, the packet forwarding rate of one line-speed port is 468MppS. \n Therefore, if we can meet the above three conditions, then we say that this switch is truly linear and non-blocking; the back-up rate of the switch is generally: \n Mbps, which refers to the second layer, which is used for the exchange of more than three layers. \n Mpps 4. The backplane bandwidth does not exist in the switch with the fixed port. \n This concept is only possible with modular switches (with scalable slots that can flexibly change the number of ports). Fixed-port switches do not have this concept, and the backplane capacity and switching capacity of fixed-port switches are equal. The backplane bandwidth determines the maximum bandwidth for the connection between each board (including boards that are not yet installed in the expandable slot) and the switching engine. Due to the different architectures of modular switches, backplane bandwidth is not fully effective at representing the true performance of the switch. Fixed port switches do not have the concept of backplane bandwidth. Second, the exchange capacity \n It is the transmission capacity of the core CPU and bus, generally smaller than the backplane bandwidth. H3C low-end LSW switching uses the store-and-forward mode. The size of the switching capacity is determined by the bit width of the buffer (BUFFER) and its bus frequency. That is, the switching capacity = cache bit width * cache bus frequency = 96 * 133 = 12.8 Gbps H3C high-end switch exchange capacity can be equal to twice the total port capacity, total port capacity = 2 * (n * 100Mbps + m * 1000Mbps) ( n: indicates that the switch has n 100M ports, m: indicates that the switch has m 1000M ports. \n 3. The packet forwarding rate forwarding capability is measured by the minimum packet length. For the Ethernet minimum packet is 64BYTE, plus the frame overhead 20BYTE. Therefore, the minimum package is 84BYTE. For a full-duplex 1000Mbps interface to achieve line speed requirements: forwarding capacity = 1000Mbps / ((64 + 20) * 8bit) = 1.488Mpps for a full-duplex 100Mbps interface to achieve line speed requirements: forwarding capacity = 100Mbps / ((64+20)*8bit)=0.149Mpps Unit: Mpps (Million packets per second) This article is from the "Snow Moon Studio" blog, please be sure to keep this source  http://xueyue8.blog.51cto.com/4650249/1765750   How is the backplane bandwidth, switching capacity, and packet forwarding rate of the switch calculated? For the manufacturers, the standard is higher than the line speed forwarding.', 'tags': '', 'url': 'Switch.html'}, {'title': 'Web Site', 'text': '利用 Github 與 Gitlab 倉儲建立個人網頁 \n 何謂網際內容管理? \n Web-based Content Management \n Content? \n 3D 零組件 \n https://www.onshape.com \n 英文學習紀錄 \n 數學學習紀錄 \n 專業課程學習紀錄 \n Video \n https://github.com/ShareX/ShareX \n https://www.blender.org/ \n Audio \n https://www.audacityteam.org/ \n Images \n https://www.gimp.org/ \n https://inkscape.org/ \n Animation \n Github 是甚麼? \n Gitlab 又是甚麼? \n 自行在 Ubuntu 操作系統上安裝 Gitlab? \n Ubuntu 操作系統? \n 實體系統 \n 虛擬系統 \n Virtualbox', 'tags': '', 'url': 'Web Site.html'}]};